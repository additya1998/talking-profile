{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/additya/NUS/src/SVM/final')\n",
    "\n",
    "\n",
    "from experiment import Experiment\n",
    "from config import *\n",
    "\n",
    "import importlib\n",
    "# importlib.reload(experiment)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv, os, sys\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from random import randint\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(svm_type, train_pos_X, train_neg_X=np.array([])):\n",
    "    \n",
    "    if svm_type == 'two-class':\n",
    "        train_pos_Y = np.ones(train_pos_X.shape[0])\n",
    "        train_neg_Y = np.zeros(train_neg_X.shape[0])    \n",
    "\n",
    "        train_X = np.vstack((train_pos_X, train_neg_X))\n",
    "        train_Y = np.hstack((train_pos_Y, train_neg_Y))\n",
    "        \n",
    "        assert(np.where(train_Y == 1)[0].shape[0] == train_pos_X.shape[0])\n",
    "        assert(np.where(train_Y == 0)[0].shape[0] == train_neg_X.shape[0])\n",
    "\n",
    "#         rus = RandomUnderSampler(return_indices=True)\n",
    "#         (train_X, train_Y, id_rus) = rus.fit_sample(train_X, train_Y)\n",
    "#         (train_X, train_Y) = shuffle(train_X, train_Y)\n",
    "        \n",
    "    else:\n",
    "        train_X = train_pos_X\n",
    "        train_Y = np.ones(train_pos_X.shape[0])\n",
    "    \n",
    "    print(\"Number of Train Positive Samples:\", train_pos_X.shape[0])\n",
    "    print(\"Number of Train Negative Samples:\", train_neg_X.shape[0])\n",
    "    \n",
    "    if svm_type == 'two-class':\n",
    "        clf = SVC(probability=True, gamma='scale')\n",
    "        clf.fit(train_X, train_Y)\n",
    "    elif svm_type == 'one-class':\n",
    "        clf = OneClassSVM(gamma='scale')\n",
    "        clf.fit(train_X)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def get_preds(clf, test_X, clf_type):\n",
    "    if clf_type == 'two-class':\n",
    "        return clf.predict_proba(test_X)[:, 1]\n",
    "    elif clf_type == 'one-class':\n",
    "        preds = clf.decision_function(test_X)\n",
    "        MAX = np.max(preds)\n",
    "        preds = MAX - preds\n",
    "        MAX = np.max(preds)\n",
    "        preds = MAX - preds\n",
    "        return preds\n",
    "\n",
    "def evaluate_preds(preds, test_Y, svm_type):\n",
    "    if svm_type == 'two-class':\n",
    "        fpr, tpr, thresholds = roc_curve(test_Y, preds, drop_intermediate=False)\n",
    "        auc_score = np.round(roc_auc_score(test_Y, preds), 8)\n",
    "        return auc_score\n",
    "    elif svm_type == 'one-class':\n",
    "        return np.round(average_precision_score(test_Y, preds), 8)\n",
    "    else:\n",
    "        print('invalid SVM')\n",
    "        raise\n",
    "\n",
    "def get_fake_list(preds):\n",
    "    fake_list, idx = [], 0\n",
    "    while idx < preds.shape[0]:\n",
    "        idx = idx\n",
    "        if preds[idx] == 0:\n",
    "            fake_list.append((idx, idx))\n",
    "            while preds[idx] == 0:\n",
    "                (x, y) = fake_list[-1]\n",
    "                fake_list[-1] = (x, idx)\n",
    "                idx += 1\n",
    "                if idx == preds.shape[0]:\n",
    "                    break\n",
    "        else:\n",
    "            idx = idx + 1\n",
    "    return fake_list\n",
    "\n",
    "def get_intersection(start_A, end_A, start_B, end_B):\n",
    "    if (start_A > end_B) or (start_B > end_A):\n",
    "        return (-1, -1)\n",
    "    (intersection_s, intersection_e) = (max(start_A, start_B), min(end_A, end_B))\n",
    "    return (intersection_s, intersection_e)\n",
    "    \n",
    "def intersection_over_union(preds, labels):\n",
    "    \n",
    "    new_preds = np.ones(preds.shape[0])\n",
    "    pred_fake_idx = np.where(preds < 0.6)[0]\n",
    "    new_preds[pred_fake_idx] = 0\n",
    "      \n",
    "    union = np.unique(np.concatenate((np.where(new_preds == 0)[0], np.where(labels == 0)[0]), 0)).shape[0]\n",
    "    intersection = np.intersect1d(np.where(new_preds == 0)[0], np.where(labels == 0)[0]).shape[0]\n",
    "    \n",
    "    return np.round(float(intersection) / union, 8)\n",
    "\n",
    "#     fake_list = get_fake_list(new_preds)\n",
    "    \n",
    "#     if len(fake_list) == 0:\n",
    "#         return 0\n",
    "        \n",
    "#     if len(fake_list) > 1:\n",
    "#         (X, Y, min_changes) = (0, 0, new_preds.shape[0] + 1)\n",
    "#         for st in range(len(fake_list)):\n",
    "#             for en in range(st, len(fake_list)):\n",
    "#                 fake_start, _ = fake_list[st]\n",
    "#                 _, fake_end = fake_list[en]\n",
    "#                 changes = np.where(new_preds[:fake_start] == 0)[0].shape[0] + \\\n",
    "#                              np.where(new_preds[fake_start:fake_end + 1] == 1)[0].shape[0] + \\\n",
    "#                              np.where(new_preds[fake_end + 1:] == 0)[0].shape[0]\n",
    "#                 if (changes < min_changes) or ((changes == min_changes) and (fake_end - fake_start > Y - X)):\n",
    "#                     min_changes = changes\n",
    "#                     (X, Y) = (fake_start, fake_end)\n",
    "\n",
    "#         new_preds[:X] = 1\n",
    "#         new_preds[X:Y + 1] = 0\n",
    "#         new_preds[Y + 1:] = 1\n",
    "\n",
    "#     fake_list = get_fake_list(new_preds) \n",
    "#     assert(len(fake_list) == 1)\n",
    "    \n",
    "#     (pred_s, pred_e) = fake_list[0]\n",
    "    \n",
    "#     fake_idx = np.where(labels == 0)[0]\n",
    "#     (fake_s, fake_e) = (np.min(fake_idx), np.max(fake_idx))\n",
    "    \n",
    "#     (intersection_s, intersection_e) = get_intersection(fake_s, fake_e, pred_s, pred_e)\n",
    "#     if intersection_s == intersection_e == -1:\n",
    "#         intersection = 0\n",
    "#     else:\n",
    "#         intersection = intersection_e - intersection_s + 1\n",
    "#     union = (pred_e - pred_s + 1) + (fake_e - fake_s + 1) - intersection\n",
    "    \n",
    "#     return np.round(float(intersection) / union, 8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_new(e, svm_type, iterr=50):\n",
    "    e.total_correct_added, e.total_wrong_added = 0, 0\n",
    "    e.initial_auc, e.final_auc = -1, -1\n",
    "    e.initial_iou, e.final_iou = -1, -1\n",
    "    probability_cutoff, frq_cutoff = 0.80, 25\n",
    "    e.auc_arr = []\n",
    "    e.iou_arr = []\n",
    "    e.iterr = iterr\n",
    "    e.svm_type = svm_type\n",
    "    \n",
    "    frames_right = (e.frame_length - 1) // 2\n",
    "    (count_A, count_B, count_C) = (e.fake_s - 1 - e.train_last_center_frame, e.fake_e - e.fake_s + 1, e.features.shape[0] - 1 - frames_right - e.fake_e - 1)\n",
    "    labels_in_order = np.hstack((np.ones(count_A), np.zeros(count_B)))\n",
    "    labels_in_order = np.hstack((labels_in_order, np.ones(count_C)))\n",
    "    print(count_A, count_B, count_C)\n",
    "    print(labels_in_order.shape[0])\n",
    "    assert(labels_in_order.shape[0] == count_A + count_B + count_C)\n",
    "    \n",
    "    for it in range(e.iterr):\n",
    "        \n",
    "        print(\"#\" * 100)\n",
    "        print(\"Iteration:\", it)\n",
    "\n",
    "        print(\"# train positive:\", e.train_positive.shape[0])\n",
    "        print(\"# train negative:\", e.train_negative.shape[0])\n",
    "        print(\"# test positive:\", e.test_positive.shape[0])\n",
    "        print(\"# test negative:\", e.test_negative.shape[0])\n",
    "\n",
    "        clf = get_classifier(e.svm_type, e.train_positive, e.train_negative)\n",
    "        test_X = np.vstack((e.test_positive, e.test_negative))\n",
    "        test_Y = np.hstack((np.ones(e.test_positive.shape[0]), np.zeros(e.test_negative.shape[0])))\n",
    "        preds = get_preds(clf, test_X, e.svm_type)\n",
    "        \n",
    "        auc_score = evaluate_preds(preds, test_Y, e.svm_type)\n",
    "        if auc_score < 0.5:\n",
    "            preds = 1 - preds\n",
    "            auc_score = 1 - auc_score\n",
    "\n",
    "        original_auc_score = auc_score\n",
    "        auc_score = np.round(auc_score, 2)\n",
    "        \n",
    "        \n",
    "        print(\">>>>>AUC:\", auc_score)\n",
    "        \n",
    "        if e.initial_auc == -1:\n",
    "            e.initial_auc = auc_score\n",
    "        e.final_auc = auc_score\n",
    "        e.auc_arr.append(auc_score)\n",
    "        \n",
    "        preds_in_order = np.hstack((preds[:count_A], preds[count_A + count_C:], preds[count_A:count_A + count_C]))\n",
    "        assert(preds_in_order.shape[0] == preds.shape[0])\n",
    "        \n",
    "#         return (preds_in_order, labels_in_order)\n",
    "        \n",
    "        iou_score = np.round(intersection_over_union(preds_in_order, labels_in_order), 2)        \n",
    "        \n",
    "        if e.initial_iou == -1:\n",
    "            e.initial_iou = iou_score\n",
    "        e.final_iou = iou_score\n",
    "        print(\">>>>>IOU:\", iou_score)\n",
    "        \n",
    "        new_auc_score = evaluate_preds(preds_in_order, labels_in_order, e.svm_type)\n",
    "        if new_auc_score < 0.5:\n",
    "            new_auc_score = 1 - new_auc_score\n",
    "        if e.svm_type == 'two-class' and abs(new_auc_score - original_auc_score) > 0.0001:\n",
    "            print(\"#\"*20, \"LABELS ORDER ERROR!\", \"#\"*20)\n",
    "            print(new_auc_score, original_auc_score)\n",
    "            \n",
    "        if (it > 0) and (it % 10 == 0):\n",
    "            frq_cutoff += 10\n",
    "            frq_cutoff = min(frq_cutoff, 100)\n",
    "            probability_cutoff += 0.01\n",
    "            probability_cutoff = min(probability_cutoff, 0.9)\n",
    "\n",
    "        all_idx = preds.argsort()[::-1]\n",
    "        if e.svm_type == 'two-class':\n",
    "            pos_train_idx = np.array([i for i in all_idx if i not in e.added_idx and preds[i] > probability_cutoff])\n",
    "        else:\n",
    "            pos_train_idx = np.array([i for i in all_idx if i not in e.added_idx])\n",
    "        pos_train_idx = pos_train_idx[:min(pos_train_idx.shape[0], frq_cutoff)]\n",
    "\n",
    "        if len(pos_train_idx) == 0:\n",
    "            print(\"Nothing to add, breaking!\")\n",
    "            break\n",
    "\n",
    "        e.train_positive = np.vstack((e.train_positive, test_X[pos_train_idx]))\n",
    "        print(\"# positive samples added =\", pos_train_idx.shape[0])\n",
    "        e.added_idx = np.hstack((e.added_idx, pos_train_idx))\n",
    "\n",
    "        CORR = (np.where(test_Y[pos_train_idx] == 1)[0].shape[0])\n",
    "        WR = (np.where(test_Y[pos_train_idx] == 0)[0].shape[0])\n",
    "\n",
    "        e.total_correct_added += CORR\n",
    "        e.total_wrong_added += WR\n",
    "\n",
    "        print(\"Correct Added:\", CORR)\n",
    "        print(\"Wrong Added:\", WR)\n",
    "        print(\"Total Correct Added:\", e.total_correct_added)\n",
    "        print(\"Total Wrong Added:\", e.total_wrong_added)    \n",
    "\n",
    "        print(\"#\" * 100)\n",
    "\n",
    "    print('>>>>>>>>>>>>>>>>>>>>AUC', e.initial_auc, e.final_auc)\n",
    "    print('>>>>>>>>>>>>>>>>>>>>IOU', e.initial_iou, e.final_iou)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(e, svm_type, iterr=100):\n",
    "    e.total_correct_added, e.total_wrong_added = 0, 0\n",
    "    e.initial_auc, e.final_auc = -1, -1\n",
    "    e.initial_iou, e.final_iou = -1, -1\n",
    "    probability_cutoff, frq_cutoff = 0.90, 25\n",
    "    e.auc_arr = []\n",
    "    e.iou_arr = []\n",
    "    e.iterr = iterr\n",
    "    e.svm_type = svm_type\n",
    "    \n",
    "    frames_right = (e.frame_length - 1) // 2\n",
    "    (count_A, count_B, count_C) = (e.fake_s - 1 - e.train_last_center_frame, e.fake_e - e.fake_s + 1, e.features.shape[0] - 1 - frames_right - e.fake_e - 1)\n",
    "    labels_in_order = np.hstack((np.ones(count_A), np.zeros(count_B)))\n",
    "    labels_in_order = np.hstack((labels_in_order, np.ones(count_C)))\n",
    "    print(count_A, count_B, count_C)\n",
    "    print(labels_in_order.shape[0])\n",
    "    assert(labels_in_order.shape[0] == count_A + count_B + count_C)\n",
    "    \n",
    "    for it in range(e.iterr):\n",
    "        \n",
    "        print(\"#\" * 100)\n",
    "        print(\"Iteration:\", it)\n",
    "\n",
    "        print(\"# train positive:\", e.train_positive.shape[0])\n",
    "        print(\"# train negative:\", e.train_negative.shape[0])\n",
    "        print(\"# test positive:\", e.test_positive.shape[0])\n",
    "        print(\"# test negative:\", e.test_negative.shape[0])\n",
    "\n",
    "        clf = get_classifier(e.svm_type, e.train_positive, e.train_negative)\n",
    "        test_X = np.vstack((e.test_positive, e.test_negative))\n",
    "        test_Y = np.hstack((np.ones(e.test_positive.shape[0]), np.zeros(e.test_negative.shape[0])))\n",
    "        preds = get_preds(clf, test_X, e.svm_type)\n",
    "        \n",
    "        auc_score = evaluate_preds(preds, test_Y, e.svm_type)\n",
    "        if auc_score < 0.5:\n",
    "            preds = 1 - preds\n",
    "            auc_score = 1 - auc_score\n",
    "\n",
    "        original_auc_score = auc_score\n",
    "        auc_score = np.round(auc_score, 2)\n",
    "        \n",
    "        \n",
    "        print(\">>>>>AUC:\", auc_score)\n",
    "        \n",
    "        if e.initial_auc == -1:\n",
    "            e.initial_auc = auc_score\n",
    "        e.final_auc = auc_score\n",
    "        e.auc_arr.append(auc_score)\n",
    "        \n",
    "        preds_in_order = np.hstack((preds[:count_A], preds[count_A + count_C:], preds[count_A:count_A + count_C]))\n",
    "        assert(preds_in_order.shape[0] == preds.shape[0])\n",
    "        iou_score = np.round(intersection_over_union(preds_in_order, labels_in_order), 2)        \n",
    "        \n",
    "#         return (preds_in_order, labels_in_order)\n",
    "        \n",
    "        if e.initial_iou == -1:\n",
    "            e.initial_iou = iou_score\n",
    "        e.final_iou = iou_score\n",
    "        print(\">>>>>IOU:\", iou_score)\n",
    "        \n",
    "        new_auc_score = evaluate_preds(preds_in_order, labels_in_order, e.svm_type)\n",
    "        if new_auc_score < 0.5:\n",
    "            new_auc_score = 1 - new_auc_score\n",
    "        if e.svm_type == 'two-class' and abs(new_auc_score - original_auc_score) > 0.0001:\n",
    "            print(\"#\"*20, \"LABELS ORDER ERROR!\", \"#\"*20)\n",
    "            print(new_auc_score, original_auc_score)\n",
    "        \n",
    "        if (it > 0) and (it % 10 == 0):\n",
    "            probability_cutoff -= 0.01\n",
    "            frq_cutoff += 10\n",
    "            probability_cutoff = max(probability_cutoff, 0.8)\n",
    "            frq_cutoff = min(frq_cutoff, 100)\n",
    "\n",
    "        all_idx = preds.argsort()[::-1]\n",
    "        if e.svm_type == 'two-class':\n",
    "            pos_train_idx = np.array([i for i in all_idx if i not in e.added_idx and preds[i] > probability_cutoff])\n",
    "        else:\n",
    "            pos_train_idx = np.array([i for i in all_idx if i not in e.added_idx])\n",
    "        pos_train_idx = pos_train_idx[:min(pos_train_idx.shape[0], frq_cutoff)]\n",
    "\n",
    "        if len(pos_train_idx) == 0:\n",
    "            print(\"Nothing to add, breaking!\")\n",
    "            break\n",
    "\n",
    "        e.train_positive = np.vstack((e.train_positive, test_X[pos_train_idx]))\n",
    "        print(\"# positive samples added =\", pos_train_idx.shape[0])\n",
    "        e.added_idx = np.hstack((e.added_idx, pos_train_idx))\n",
    "\n",
    "        CORR = (np.where(test_Y[pos_train_idx] == 1)[0].shape[0])\n",
    "        WR = (np.where(test_Y[pos_train_idx] == 0)[0].shape[0])\n",
    "\n",
    "        e.total_correct_added += CORR\n",
    "        e.total_wrong_added += WR\n",
    "\n",
    "        print(\"Correct Added:\", CORR)\n",
    "        print(\"Wrong Added:\", WR)\n",
    "        print(\"Total Correct Added:\", e.total_correct_added)\n",
    "        print(\"Total Wrong Added:\", e.total_wrong_added)    \n",
    "\n",
    "        print(\"#\" * 100)\n",
    "\n",
    "    print('>>>>>>>>>>>>>>>>>>>>AUC', e.initial_auc, e.final_auc)\n",
    "    print('>>>>>>>>>>>>>>>>>>>>IOU', e.initial_iou, e.final_iou)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_keys = [420, 421, 423, 445, 496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dict = {}\n",
    "for key in [420]:\n",
    "    e_dict[key] = {}\n",
    "    for fake_type in ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "        for fl in [50, 75, 100]:\n",
    "            for s in [50, 100, 250]:\n",
    "                try:\n",
    "                    print(\"starting:\", key, fake_type, fl, s)\n",
    "                    e_dict[key][(fake_type, 'original', 'two-class', fl, s)] = Experiment(key, fake_type, 'original', 'original', 'two-class', fl, s)\n",
    "                    e_dict[key][(fake_type, 'au_corr', 'two-class', fl, s)] = Experiment(key, fake_type, 'au', 'corr', 'two-class', fl, s)\n",
    "                    e_dict[key][(fake_type, 'au_corr', 'one-class', fl, s)] = Experiment(key, fake_type, 'au', 'corr', 'one-class', fl, s)\n",
    "                    print(\"done:\", key, fake_type, fl, s)\n",
    "                except:\n",
    "                    print(\"Not done:\", key, fake_type, fl, s)\n",
    "                    \n",
    "for key in [420]:\n",
    "    for fake_type in ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "        for fl in [50, 75, 100]:\n",
    "            for s in [50, 100, 250]:\n",
    "                try:\n",
    "                    print(\"=\"*20, key, fake_type, \"original two-class\", \"=\"*20)\n",
    "                    run_experiment(e_dict[key][(fake_type, 'original', 'two-class', fl, s)], 'two-class')\n",
    "                    print(\"DONE ORIGINAL TWO-CLASS\", key, fake_type, fl, s)\n",
    "        \n",
    "                    print(\"=\"*20, key, fake_type, \"au_corr one-class\", \"=\"*20)\n",
    "                    run_experiment(e_dict[key][(fake_type, 'au_corr', 'one-class', fl, s)], 'one-class')\n",
    "                    print(\"DONE AU CORR ONE-CLASS\", key, fake_type, fl, s)\n",
    "\n",
    "                    print(\"=\"*20, key, fake_type, \"au_corr two-class\", \"=\"*20)\n",
    "                    run_experiment(e_dict[key][(fake_type, 'au_corr', 'two-class', fl, s)], 'two-class')\n",
    "                    print(\"DONE AU CORR TWO-CLASS\", key, fake_type, fl, s) \n",
    "                except:\n",
    "                    print(\"Error\", key, fake_type, fl, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
